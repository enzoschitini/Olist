{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11586, 46)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>order_item_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>customer_unique_id</th>\n",
       "      <th>customer_zip_code_prefix</th>\n",
       "      <th>customer_city</th>\n",
       "      <th>customer_state</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_category_name</th>\n",
       "      <th>product_name_lenght</th>\n",
       "      <th>...</th>\n",
       "      <th>year_of_purchase</th>\n",
       "      <th>month/year_of_purchase</th>\n",
       "      <th>order_status</th>\n",
       "      <th>order_unique_id</th>\n",
       "      <th>review_id</th>\n",
       "      <th>review_score</th>\n",
       "      <th>review_comment_title</th>\n",
       "      <th>review_comment_message</th>\n",
       "      <th>review_creation_date</th>\n",
       "      <th>review_answer_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>532ed5e14e24ae1f0d735b91524b98b9</td>\n",
       "      <td>1</td>\n",
       "      <td>4ef55bf80f711b372afebcb7c715344a</td>\n",
       "      <td>3419052c8c6b45daf79c1e426f9e9bcb</td>\n",
       "      <td>30720</td>\n",
       "      <td>belo horizonte</td>\n",
       "      <td>MG</td>\n",
       "      <td>4244733e06e7ecb4970a6e2683c13e61</td>\n",
       "      <td>cool_stuff</td>\n",
       "      <td>58.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2018</td>\n",
       "      <td>May-2018</td>\n",
       "      <td>delivered</td>\n",
       "      <td>532ed5e14e24ae1f0d735b91524b98b9-1</td>\n",
       "      <td>af01c4017c5ab46df6cc810e069e654a</td>\n",
       "      <td>4</td>\n",
       "      <td>super recomendo</td>\n",
       "      <td>carrinho muito bonito</td>\n",
       "      <td>2018-06-05 00:00:00</td>\n",
       "      <td>2018-06-06 21:41:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>1432d48030ced821a4afaabcfc2a8b0f</td>\n",
       "      <td>1</td>\n",
       "      <td>6a909b62463d9c6cc4126cea7af3ad59</td>\n",
       "      <td>7b06aa5473c44b8e05b9eeaea702f1a2</td>\n",
       "      <td>4026</td>\n",
       "      <td>sao paulo</td>\n",
       "      <td>SP</td>\n",
       "      <td>e1da6ab77f4859eb17950e5df1c0f815</td>\n",
       "      <td>pet_shop</td>\n",
       "      <td>56.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2018</td>\n",
       "      <td>June-2018</td>\n",
       "      <td>delivered</td>\n",
       "      <td>1432d48030ced821a4afaabcfc2a8b0f-1</td>\n",
       "      <td>14ab06af2677555bfcf9ff2e64a1b203</td>\n",
       "      <td>1</td>\n",
       "      <td>O produto não foi entregu</td>\n",
       "      <td>Sem satisfação sobre atraso na entrega</td>\n",
       "      <td>2018-06-12 00:00:00</td>\n",
       "      <td>2018-06-20 10:49:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>6f21315112f543e3009995c7d0391473</td>\n",
       "      <td>1</td>\n",
       "      <td>070bca17bc76a393ba985b11b2f9deda</td>\n",
       "      <td>7942503b866fda5908a460d4c80ede0f</td>\n",
       "      <td>83260</td>\n",
       "      <td>matinhos</td>\n",
       "      <td>PR</td>\n",
       "      <td>e1da6ab77f4859eb17950e5df1c0f815</td>\n",
       "      <td>pet_shop</td>\n",
       "      <td>56.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2018</td>\n",
       "      <td>April-2018</td>\n",
       "      <td>delivered</td>\n",
       "      <td>6f21315112f543e3009995c7d0391473-1</td>\n",
       "      <td>2ac001436562c8aea94745da1c90e463</td>\n",
       "      <td>4</td>\n",
       "      <td>Muito bom</td>\n",
       "      <td>Produto muito bom</td>\n",
       "      <td>2018-05-09 00:00:00</td>\n",
       "      <td>2018-05-24 18:13:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>6f21315112f543e3009995c7d0391473</td>\n",
       "      <td>2</td>\n",
       "      <td>070bca17bc76a393ba985b11b2f9deda</td>\n",
       "      <td>7942503b866fda5908a460d4c80ede0f</td>\n",
       "      <td>83260</td>\n",
       "      <td>matinhos</td>\n",
       "      <td>PR</td>\n",
       "      <td>e1da6ab77f4859eb17950e5df1c0f815</td>\n",
       "      <td>pet_shop</td>\n",
       "      <td>56.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2018</td>\n",
       "      <td>April-2018</td>\n",
       "      <td>delivered</td>\n",
       "      <td>6f21315112f543e3009995c7d0391473-2</td>\n",
       "      <td>2ac001436562c8aea94745da1c90e463</td>\n",
       "      <td>4</td>\n",
       "      <td>Muito bom</td>\n",
       "      <td>Produto muito bom</td>\n",
       "      <td>2018-05-09 00:00:00</td>\n",
       "      <td>2018-05-24 18:13:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>bc6e05c3335f87caadbcd6c80de46ad2</td>\n",
       "      <td>1</td>\n",
       "      <td>05e54a5f9eb2f443192d44067147a451</td>\n",
       "      <td>89d481231e8b8bb6e22dcb28d19e5378</td>\n",
       "      <td>50820</td>\n",
       "      <td>recife</td>\n",
       "      <td>PE</td>\n",
       "      <td>e1da6ab77f4859eb17950e5df1c0f815</td>\n",
       "      <td>pet_shop</td>\n",
       "      <td>56.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2018</td>\n",
       "      <td>April-2018</td>\n",
       "      <td>delivered</td>\n",
       "      <td>bc6e05c3335f87caadbcd6c80de46ad2-1</td>\n",
       "      <td>62db97a46c640426905d92a32373fb96</td>\n",
       "      <td>5</td>\n",
       "      <td>SUPER RECOMENDO</td>\n",
       "      <td>Gostei bastante do produto e meu gatinho també...</td>\n",
       "      <td>2018-04-28 00:00:00</td>\n",
       "      <td>2018-04-29 03:30:09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             order_id  order_item_id  \\\n",
       "2    532ed5e14e24ae1f0d735b91524b98b9              1   \n",
       "180  1432d48030ced821a4afaabcfc2a8b0f              1   \n",
       "188  6f21315112f543e3009995c7d0391473              1   \n",
       "189  6f21315112f543e3009995c7d0391473              2   \n",
       "204  bc6e05c3335f87caadbcd6c80de46ad2              1   \n",
       "\n",
       "                          customer_id                customer_unique_id  \\\n",
       "2    4ef55bf80f711b372afebcb7c715344a  3419052c8c6b45daf79c1e426f9e9bcb   \n",
       "180  6a909b62463d9c6cc4126cea7af3ad59  7b06aa5473c44b8e05b9eeaea702f1a2   \n",
       "188  070bca17bc76a393ba985b11b2f9deda  7942503b866fda5908a460d4c80ede0f   \n",
       "189  070bca17bc76a393ba985b11b2f9deda  7942503b866fda5908a460d4c80ede0f   \n",
       "204  05e54a5f9eb2f443192d44067147a451  89d481231e8b8bb6e22dcb28d19e5378   \n",
       "\n",
       "     customer_zip_code_prefix   customer_city customer_state  \\\n",
       "2                       30720  belo horizonte             MG   \n",
       "180                      4026       sao paulo             SP   \n",
       "188                     83260        matinhos             PR   \n",
       "189                     83260        matinhos             PR   \n",
       "204                     50820          recife             PE   \n",
       "\n",
       "                           product_id product_category_name  \\\n",
       "2    4244733e06e7ecb4970a6e2683c13e61            cool_stuff   \n",
       "180  e1da6ab77f4859eb17950e5df1c0f815              pet_shop   \n",
       "188  e1da6ab77f4859eb17950e5df1c0f815              pet_shop   \n",
       "189  e1da6ab77f4859eb17950e5df1c0f815              pet_shop   \n",
       "204  e1da6ab77f4859eb17950e5df1c0f815              pet_shop   \n",
       "\n",
       "     product_name_lenght  ...  year_of_purchase  month/year_of_purchase  \\\n",
       "2                   58.0  ...              2018                May-2018   \n",
       "180                 56.0  ...              2018               June-2018   \n",
       "188                 56.0  ...              2018              April-2018   \n",
       "189                 56.0  ...              2018              April-2018   \n",
       "204                 56.0  ...              2018              April-2018   \n",
       "\n",
       "     order_status                     order_unique_id  \\\n",
       "2       delivered  532ed5e14e24ae1f0d735b91524b98b9-1   \n",
       "180     delivered  1432d48030ced821a4afaabcfc2a8b0f-1   \n",
       "188     delivered  6f21315112f543e3009995c7d0391473-1   \n",
       "189     delivered  6f21315112f543e3009995c7d0391473-2   \n",
       "204     delivered  bc6e05c3335f87caadbcd6c80de46ad2-1   \n",
       "\n",
       "                            review_id  review_score  \\\n",
       "2    af01c4017c5ab46df6cc810e069e654a             4   \n",
       "180  14ab06af2677555bfcf9ff2e64a1b203             1   \n",
       "188  2ac001436562c8aea94745da1c90e463             4   \n",
       "189  2ac001436562c8aea94745da1c90e463             4   \n",
       "204  62db97a46c640426905d92a32373fb96             5   \n",
       "\n",
       "          review_comment_title  \\\n",
       "2              super recomendo   \n",
       "180  O produto não foi entregu   \n",
       "188                  Muito bom   \n",
       "189                  Muito bom   \n",
       "204            SUPER RECOMENDO   \n",
       "\n",
       "                                review_comment_message review_creation_date  \\\n",
       "2                                carrinho muito bonito  2018-06-05 00:00:00   \n",
       "180             Sem satisfação sobre atraso na entrega  2018-06-12 00:00:00   \n",
       "188                                  Produto muito bom  2018-05-09 00:00:00   \n",
       "189                                  Produto muito bom  2018-05-09 00:00:00   \n",
       "204  Gostei bastante do produto e meu gatinho també...  2018-04-28 00:00:00   \n",
       "\n",
       "     review_answer_timestamp  \n",
       "2        2018-06-06 21:41:12  \n",
       "180      2018-06-20 10:49:09  \n",
       "188      2018-05-24 18:13:49  \n",
       "189      2018-05-24 18:13:49  \n",
       "204      2018-04-29 03:30:09  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews = pd.read_csv('reviews.csv').drop(columns='Unnamed: 0')\n",
    "reviews.dropna(inplace=True)\n",
    "print(reviews.shape)\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_comment_title</th>\n",
       "      <th>review_comment_message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>Qualidade ruim!</td>\n",
       "      <td>A capa protetora não é exatamente o que eu esp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>produto incorreto</td>\n",
       "      <td>O produto não está nas medidas corretas indica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818</th>\n",
       "      <td>Entrega de encomenda</td>\n",
       "      <td>Penso que deveria haver um modo de se comunica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1208</th>\n",
       "      <td>Bebedouro</td>\n",
       "      <td>Bom dia ... comprei um bebedouro vermelho metá...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337</th>\n",
       "      <td>Produto errado</td>\n",
       "      <td>Pedi duas carteiras. Uma veio com defeito e ou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98492</th>\n",
       "      <td>Atraso na entrega do prod</td>\n",
       "      <td>O prazo para entrega era dia 14/05 e até agora...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98647</th>\n",
       "      <td>Compra</td>\n",
       "      <td>Um demora pra entrega</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98917</th>\n",
       "      <td>Produto com Defeito</td>\n",
       "      <td>O produto adquirido não pode ser utilizado, o ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99117</th>\n",
       "      <td>Rápido porém não bom</td>\n",
       "      <td>Eu recebi o produto no prazo porém já veio lig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99200</th>\n",
       "      <td>Foto enganosa</td>\n",
       "      <td>Foto muito diferente principalmente a graninha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>458 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            review_comment_title  \\\n",
       "336              Qualidade ruim!   \n",
       "685            produto incorreto   \n",
       "818         Entrega de encomenda   \n",
       "1208                   Bebedouro   \n",
       "1337             Produto errado    \n",
       "...                          ...   \n",
       "98492  Atraso na entrega do prod   \n",
       "98647                     Compra   \n",
       "98917        Produto com Defeito   \n",
       "99117       Rápido porém não bom   \n",
       "99200             Foto enganosa    \n",
       "\n",
       "                                  review_comment_message  \n",
       "336    A capa protetora não é exatamente o que eu esp...  \n",
       "685    O produto não está nas medidas corretas indica...  \n",
       "818    Penso que deveria haver um modo de se comunica...  \n",
       "1208   Bom dia ... comprei um bebedouro vermelho metá...  \n",
       "1337   Pedi duas carteiras. Uma veio com defeito e ou...  \n",
       "...                                                  ...  \n",
       "98492  O prazo para entrega era dia 14/05 e até agora...  \n",
       "98647                              Um demora pra entrega  \n",
       "98917  O produto adquirido não pode ser utilizado, o ...  \n",
       "99117  Eu recebi o produto no prazo porém já veio lig...  \n",
       "99200  Foto muito diferente principalmente a graninha...  \n",
       "\n",
       "[458 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews[reviews['review_score'] == 2][['review_comment_title', 'review_comment_message']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review_score\n",
       "5    5422\n",
       "1    1789\n",
       "4    1433\n",
       "3     737\n",
       "2     458\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews['review_score'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ['recomendo', 'Super recomendo', 'Não chegou meu produto', 'Ótimo']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Carica i commenti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "commenti = ['recomendo', 'Super recomendo', 'Não chegou meu produto', 'Ótimo']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Pulizia dei commenti\n",
    "Per commenti così brevi, potresti voler normalizzarli (trasformarli in minuscolo, rimuovere caratteri speciali, ecc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['recomendo', 'super recomendo', 'não chegou meu produto', 'ótimo']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Funzione di pulizia\n",
    "def pulisci_commento(commento):\n",
    "    commento = commento.lower()\n",
    "    commento = re.sub(r'[^a-zà-ú\\s]', '', commento)  # Rimuove caratteri speciali\n",
    "    return commento\n",
    "\n",
    "# Applica la pulizia a tutti i commenti\n",
    "commenti_puliti = [pulisci_commento(c) for c in commenti]\n",
    "print(commenti_puliti)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Tokenizzazione\n",
    "Puoi trasformare ogni commento in una lista di parole."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\schit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt_tab')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\schit/nltk_data'\n    - 'c:\\\\Users\\\\schit\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\nltk_data'\n    - 'c:\\\\Users\\\\schit\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\share\\\\nltk_data'\n    - 'c:\\\\Users\\\\schit\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\schit\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m nltk\u001b[38;5;241m.\u001b[39mdownload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpunkt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Tokenizzazione\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m commenti_tokenizzati \u001b[38;5;241m=\u001b[39m [\u001b[43mword_tokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommento\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m commento \u001b[38;5;129;01min\u001b[39;00m commenti_puliti]\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(commenti_tokenizzati)\n",
      "File \u001b[1;32mc:\\Users\\schit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\nltk\\tokenize\\__init__.py:142\u001b[0m, in \u001b[0;36mword_tokenize\u001b[1;34m(text, language, preserve_line)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mword_tokenize\u001b[39m(text, language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m, preserve_line\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    128\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;124;03m    Return a tokenized copy of *text*,\u001b[39;00m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;124;03m    using NLTK's recommended word tokenizer\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;124;03m    :type preserve_line: bool\u001b[39;00m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 142\u001b[0m     sentences \u001b[38;5;241m=\u001b[39m [text] \u001b[38;5;28;01mif\u001b[39;00m preserve_line \u001b[38;5;28;01melse\u001b[39;00m \u001b[43msent_tokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m    144\u001b[0m         token \u001b[38;5;28;01mfor\u001b[39;00m sent \u001b[38;5;129;01min\u001b[39;00m sentences \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m _treebank_word_tokenizer\u001b[38;5;241m.\u001b[39mtokenize(sent)\n\u001b[0;32m    145\u001b[0m     ]\n",
      "File \u001b[1;32mc:\\Users\\schit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\nltk\\tokenize\\__init__.py:119\u001b[0m, in \u001b[0;36msent_tokenize\u001b[1;34m(text, language)\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msent_tokenize\u001b[39m(text, language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    110\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;124;03m    Return a sentence-tokenized copy of *text*,\u001b[39;00m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;124;03m    using NLTK's recommended sentence tokenizer\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;124;03m    :param language: the model name in the Punkt corpus\u001b[39;00m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 119\u001b[0m     tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43m_get_punkt_tokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer\u001b[38;5;241m.\u001b[39mtokenize(text)\n",
      "File \u001b[1;32mc:\\Users\\schit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\nltk\\tokenize\\__init__.py:105\u001b[0m, in \u001b[0;36m_get_punkt_tokenizer\u001b[1;34m(language)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mlru_cache\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_punkt_tokenizer\u001b[39m(language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     98\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;124;03m    A constructor for the PunktTokenizer that utilizes\u001b[39;00m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;124;03m    a lru cache for performance.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;124;03m    :type language: str\u001b[39;00m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPunktTokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\schit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\nltk\\tokenize\\punkt.py:1744\u001b[0m, in \u001b[0;36mPunktTokenizer.__init__\u001b[1;34m(self, lang)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, lang\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m   1743\u001b[0m     PunktSentenceTokenizer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m-> 1744\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_lang\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlang\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\schit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\nltk\\tokenize\\punkt.py:1749\u001b[0m, in \u001b[0;36mPunktTokenizer.load_lang\u001b[1;34m(self, lang)\u001b[0m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_lang\u001b[39m(\u001b[38;5;28mself\u001b[39m, lang\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m   1747\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m find\n\u001b[1;32m-> 1749\u001b[0m     lang_dir \u001b[38;5;241m=\u001b[39m \u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtokenizers/punkt_tab/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mlang\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1750\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_params \u001b[38;5;241m=\u001b[39m load_punkt_params(lang_dir)\n\u001b[0;32m   1751\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lang \u001b[38;5;241m=\u001b[39m lang\n",
      "File \u001b[1;32mc:\\Users\\schit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\nltk\\data.py:579\u001b[0m, in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    577\u001b[0m sep \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m70\u001b[39m\n\u001b[0;32m    578\u001b[0m resource_not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 579\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt_tab')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\schit/nltk_data'\n    - 'c:\\\\Users\\\\schit\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\nltk_data'\n    - 'c:\\\\Users\\\\schit\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\share\\\\nltk_data'\n    - 'c:\\\\Users\\\\schit\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\schit\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Tokenizzazione\n",
    "commenti_tokenizzati = [word_tokenize(commento) for commento in commenti_puliti]\n",
    "print(commenti_tokenizzati)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Rimozione delle stopwords\n",
    "Le stopwords in portoghese (es. \"não\", \"meu\") possono essere rimosse per rendere l'analisi più pulita."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\schit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'commenti_tokenizzati' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [word \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m tokens \u001b[38;5;28;01mif\u001b[39;00m word \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m stop_words]\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Applica la funzione\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m commenti_senza_stopwords \u001b[38;5;241m=\u001b[39m [rimuovi_stopwords(tokens) \u001b[38;5;28;01mfor\u001b[39;00m tokens \u001b[38;5;129;01min\u001b[39;00m \u001b[43mcommenti_tokenizzati\u001b[49m]\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(commenti_senza_stopwords)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'commenti_tokenizzati' is not defined"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Scarica le stopwords in portoghese\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('portuguese'))\n",
    "\n",
    "# Funzione per rimuovere stopwords\n",
    "def rimuovi_stopwords(tokens):\n",
    "    return [word for word in tokens if word not in stop_words]\n",
    "\n",
    "# Applica la funzione\n",
    "commenti_senza_stopwords = [rimuovi_stopwords(tokens) for tokens in commenti_tokenizzati]\n",
    "print(commenti_senza_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Analisi di frequenza\n",
    "Ora puoi analizzare la frequenza delle parole nei commenti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Unisci tutti i token in una lista unica\n",
    "tutti_i_tokens = [token for tokens in commenti_senza_stopwords for token in tokens]\n",
    "\n",
    "# Conta la frequenza delle parole\n",
    "frequenza = Counter(tutti_i_tokens)\n",
    "\n",
    "# Mostra le parole più comuni\n",
    "print(frequenza.most_common(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Analisi del sentimento\n",
    "Puoi anche analizzare il sentimento dei commenti usando una libreria come TextBlob (supporta il portoghese)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "# Funzione per analizzare il sentimento\n",
    "def analisi_sentimento(commento):\n",
    "    return TextBlob(commento).sentiment.polarity\n",
    "\n",
    "# Applica la funzione per ogni commento\n",
    "sentimenti = [analisi_sentimento(c) for c in commenti_puliti]\n",
    "print(sentimenti)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualizzazione dei risultati\n",
    "Infine, puoi visualizzare i risultati della frequenza delle parole o dei sentimenti con un grafico semplice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Visualizza la frequenza delle parole\n",
    "parole, conteggi = zip(*frequenza.most_common(5))\n",
    "\n",
    "plt.bar(parole, conteggi)\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusione\n",
    "Anche con una lista breve di commenti come quella che hai fornito, puoi ottenere insight interessanti riguardo alla frequenza delle parole e al sentimento. Il flusso generale di pulizia, tokenizzazione e analisi del sentimento è simile a quello usato per dataset più grandi, ma adattato a un contesto più semplice."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
